{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AVALIAÇÃO 11"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from src.si.data.dataset import Dataset\n",
    "from src.si.io.csv import read_csv\n",
    "from src.si.neuralnets.nn import NN\n",
    "from src.si.neuralnets.layer import Dense, SigmoidActivation,SoftMaxActivation, ReLUActivation, LinearActivation\n",
    "from src.si.linear_model.ridge_regression import RidgeRegression\n",
    "from src.si.linear_model.logistic_regression import LogisticRegression\n",
    "from src.si.metrics.cross_entropy import cross_entropy, cross_entropy_derivative\n",
    "from src.si.metrics.accuracy import accuracy\n",
    "from src.si.metrics.mse import mse, mse_derivative\n",
    "from src.si.model_selection.split import train_test_split\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercício 12\n",
    "Redes neuronais e Backpropagation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "12.1) Implementa o método de backward propagation da ReLUActivation layer.\n",
    "- Considera o seguinte para a propagação do erro numa layer de ativação ReLU:\n",
    "• Substituir valores de erro superiores a 0 por 1\n",
    "• Substituir valores de erro inferiores a 0 por 0\n",
    "• Multiplicação elemento a elemento entre o erro e os valores anteriores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "12.2) Constrói um modelo de redes neuronais adequado\n",
    "ao dataset breast-bin.csv."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#dataset\n",
    "breast_dataset = read_csv('C:/Users/Carolina/Documents/GitHub/si/datasets/breast-bin.csv', sep=',',features=True, label=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[5., 1., 1., ..., 1., 1., 1.],\n       [2., 1., 1., ..., 2., 1., 1.],\n       [2., 1., 1., ..., 3., 1., 1.],\n       ...,\n       [5., 2., 2., ..., 1., 1., 2.],\n       [2., 3., 2., ..., 3., 1., 1.],\n       [7., 6., 6., ..., 7., 1., 1.]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_dataset.X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 0., 0., 1., 0., 0., 0., 0., 1., 0.])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_dataset.y[:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#standardizar o dataset\n",
    "breast_dataset.X= preprocessing.StandardScaler().fit_transform(breast_dataset.X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139, 9) (139, 9)\n",
      "(139,) (139,)\n"
     ]
    }
   ],
   "source": [
    "#dividir dataset em treino e teste\n",
    "breast_train, breast_test = train_test_split(breast_dataset)\n",
    "print(breast_train.X.shape, breast_test.X.shape)\n",
    "print(breast_train.y.shape, breast_test.y.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Dense() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [7], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# 3 layers com sigmoid activation\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m l1_bin \u001B[38;5;241m=\u001B[39m \u001B[43mDense\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m9\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m9\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m l2_bin \u001B[38;5;241m=\u001B[39m Dense(input_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m9\u001B[39m, output_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n\u001B[0;32m      5\u001B[0m l3_bin \u001B[38;5;241m=\u001B[39m Dense(input_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m4\u001B[39m, output_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[1;31mTypeError\u001B[0m: Dense() takes no arguments"
     ]
    }
   ],
   "source": [
    "# 3 layers com sigmoid activation\n",
    "\n",
    "l1_bin = Dense(input_size = 9, output_size=9)\n",
    "l2_bin = Dense(input_size = 9, output_size=4)\n",
    "l3_bin = Dense(input_size = 4, output_size=1)\n",
    "\n",
    "l1_bin_rla = ReLUActivation()\n",
    "l2_bin_rla = ReLUActivation()\n",
    "l3_bin_sa = SigmoidActivation()\n",
    "\n",
    "model_bin = NN(layers=[ l1_bin, l1_bin_rla, l2_bin, l2_bin_rla, l3_bin, l3_bin_sa], loss_function=cross_entropy, loss_derivative=cross_entropy_derivative,verbose=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_bin.fit(dataset=breast_bin_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_bin.predict(dataset=breast_bin_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred = np.where(pred>0.5, 1, 0).reshape(1,-1)\n",
    "print(pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score = accuracy(breast_bin_test.y,pred)\n",
    "print(score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "12.3) Constrói um modelo de redes neuronais adequado\n",
    "ao dataset cpu.csv."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cpu = read_csv('C:/Users/Carolina/Documents/GitHub/si/datasets/cpu.csv', sep=',',features=True, label=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cpu.y[:10]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cpu.X = preprocessing.StandardScaler().fit_transform(cpu.X)\n",
    "cpu_train, cpu_test = train_test_split(cpu, test_size=0.3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(cpu_train.shape())\n",
    "print(cpu_test.shape())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3 layers com ReLUActivation\n",
    "\n",
    "# l1_reg = Dense(input_size = 6, output_size=6)\n",
    "l2_reg = Dense(input_size = 6, output_size=4)\n",
    "l3_reg = Dense(input_size = 4, output_size=1)\n",
    "\n",
    "l1_reg_rlua = ReLUActivation()\n",
    "l2_reg_rlua = ReLUActivation()\n",
    "\n",
    "model_reg = NN(layers=[l1_reg_rlua, l2_reg, l2_reg_rlua, l3_reg], loss_function=cross_entropy, loss_derivative=cross_entropy_derivative, verbose=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_reg.fit(dataset=cpu_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred = model_reg.predict(dataset=cpu_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score = mse(cpu_test.y,pred)\n",
    "print(score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
